{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['帮我', '查下', '明天', '北京', '天气', '怎么样']\n"
     ]
    }
   ],
   "source": [
    "# 生成语料库\n",
    "\n",
    "corpus = [\n",
    "  \"帮我 查下 明天 北京 天气 怎么样\",\n",
    "  \"帮我 查下 今天 北京 天气 好不好\",\n",
    "  \"帮我 查询 去 北京 的 火车\",\n",
    "  \"帮我 查看 到 上海 的 火车\",\n",
    "  \"帮我 查看 特朗普 的 新闻\",\n",
    "  \"帮我 看看 有没有 北京 的 新闻\",\n",
    "  \"帮我 搜索 上海 有 什么 好玩的\",\n",
    "  \"帮我 找找 上海 东方明珠 在哪\"\n",
    "]\n",
    "\n",
    "\n",
    "print(corpus[0].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8] ['帮我', '查下', '明天', '北京', '天气', '怎么样', '帮我', '查下', '今天', '北京', '天气', '好不好', '帮我', '查询', '去', '北京', '的', '火车', '帮我', '查看', '到', '上海', '的', '火车', '帮我', '查看', '特朗普', '的', '新闻', '帮我', '看看', '有没有', '北京', '的', '新闻', '帮我', '搜索', '上海', '有', '什么', '好玩的', '帮我', '找找', '上海', '东方明珠', '在哪']\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "num_list = []\n",
    "word_list = []\n",
    "for ii0 in range(len(corpus)):\n",
    "    num += 1\n",
    "    word = corpus[ii0].split(' ')\n",
    "    for i in word:\n",
    "        num_list.append(num)\n",
    "        word_list.append(i)\n",
    "print(num_list, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id word\n",
      "0   1   帮我\n",
      "1   1   查下\n",
      "2   1   明天\n",
      "3   1   北京\n",
      "4   1   天气\n"
     ]
    }
   ],
   "source": [
    "# 将不同列表转换为DataFrame\n",
    "from pandas.core.frame import DataFrame\n",
    "cp = {'id':num_list, 'word':word_list}\n",
    "df = DataFrame(cp)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df.to_csv('data/corpus.csv', index=False, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>帮我</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>查下</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>明天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>北京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>天气</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id word\n",
       "0   1   帮我\n",
       "1   1   查下\n",
       "2   1   明天\n",
       "3   1   北京\n",
       "4   1   天气"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从这里开始\n",
    "# 首先导入所需要的库\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "df = pd.read_csv('corpus.csv', encoding='gbk')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8] ['帮我', '查下', '明天', '北京', '天气', '怎么样', '帮我', '查下', '今天', '北京', '天气', '好不好', '帮我', '查询', '去', '北京', '的', '火车', '帮我', '查看', '到', '上海', '的', '火车', '帮我', '查看', '特朗普', '的', '新闻', '帮我', '看看', '有没有', '北京', '的', '新闻', '帮我', '搜索', '上海', '有', '什么', '好玩的', '帮我', '找找', '上海', '东方明珠', '在哪']\n"
     ]
    }
   ],
   "source": [
    "# 将数据转化成列表\n",
    "id_list = list(df.id)\n",
    "word_list = list(df.word)\n",
    "print(id_list, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.DataFrameGroupBy object at 0x00000249E42C1B70>\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['帮我', '查下', '明天', '北京', '天气', '怎么样']\n",
      "['帮我', '查下', '今天', '北京', '天气', '好不好']\n",
      "['帮我', '查询', '去', '北京', '的', '火车']\n",
      "['帮我', '查看', '到', '上海', '的', '火车']\n",
      "['帮我', '查看', '特朗普', '的', '新闻']\n",
      "['帮我', '看看', '有没有', '北京', '的', '新闻']\n",
      "['帮我', '搜索', '上海', '有', '什么', '好玩的']\n",
      "['帮我', '找找', '上海', '东方明珠', '在哪']\n"
     ]
    }
   ],
   "source": [
    "cps = []\n",
    "for i in df.groupby(['id']):\n",
    "    seg_list = list(i[1].word)\n",
    "    print(seg_list)\n",
    "    seg = ' '.join(seg_list)\n",
    "    cps.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'明天': 1, '帮我': 1, '查下': 1, '天气': 1, '北京': 1, '怎么样': 1}\n",
      "{'帮我': 1, '查下': 1, '天气': 1, '北京': 1, '好不好': 1, '今天': 1}\n",
      "{'帮我': 1, '的': 1, '去': 1, '北京': 1, '火车': 1, '查询': 1}\n",
      "{'帮我': 1, '上海': 1, '的': 1, '到': 1, '查看': 1, '火车': 1}\n",
      "{'新闻': 1, '帮我': 1, '查看': 1, '的': 1, '特朗普': 1}\n",
      "{'帮我': 1, '的': 1, '看看': 1, '北京': 1, '新闻': 1, '有没有': 1}\n",
      "{'搜索': 1, '帮我': 1, '上海': 1, '什么': 1, '有': 1, '好玩的': 1}\n",
      "{'在哪': 1, '帮我': 1, '上海': 1, '东方明珠': 1, '找找': 1}\n"
     ]
    }
   ],
   "source": [
    "# 计算词频\n",
    "import nltk\n",
    "for i in cps:\n",
    "    ii = i.split(' ')\n",
    "    cfd = dict(nltk.FreqDist(ii))\n",
    "    print(cfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words:\n",
      "['上海', '东方明珠', '什么', '今天', '到', '北京', '去', '在哪', '天气', '好不好', '好玩的', '帮我', '怎么样', '找找', '搜索', '新闻', '明天', '有', '有没有', '查下', '查看', '查询', '火车', '特朗普', '的', '看看']\n",
      "len of bag_of_words: 26\n"
     ]
    }
   ],
   "source": [
    "# 运用sklearn的BOW方法\n",
    "\n",
    "# step 1 声明一个向量化工具vectorizer\n",
    "vectoerizer = CountVectorizer(min_df=1, max_df=1.0, token_pattern='\\\\b\\\\w+\\\\b')\n",
    "# step 2 根据语料集统计词袋（fit）\n",
    "vectoerizer.fit(corpus)\n",
    "# step 3 打印语料集的词袋信息\n",
    "bag_of_words = vectoerizer.get_feature_names()\n",
    "print(\"Bag of words:\")\n",
    "print(bag_of_words)\n",
    "print(\"len of bag_of_words:\", len(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized corpus:\n",
      "[[0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]\n",
      " [1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1]\n",
      " [1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "index of `的` is : 24\n"
     ]
    }
   ],
   "source": [
    "# step 4 将语料集转化为词袋向量（transform）\n",
    "X = vectoerizer.transform(corpus)\n",
    "# 查看数值特征\n",
    "print(\"Vectorized corpus:\")\n",
    "print(X.toarray())\n",
    "# step 5 还可以查看每个词在词袋中的索引\n",
    "print(\"index of `的` is : {}\".format(vectoerizer.vocabulary_.get('的')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海\t1.8109302162163288\n",
      "东方明珠\t2.504077396776274\n",
      "什么\t2.504077396776274\n",
      "今天\t2.504077396776274\n",
      "到\t2.504077396776274\n",
      "北京\t1.587786664902119\n",
      "去\t2.504077396776274\n",
      "在哪\t2.504077396776274\n",
      "天气\t2.09861228866811\n",
      "好不好\t2.504077396776274\n",
      "好玩的\t2.504077396776274\n",
      "帮我\t1.0\n",
      "怎么样\t2.504077396776274\n",
      "找找\t2.504077396776274\n",
      "搜索\t2.504077396776274\n",
      "新闻\t2.09861228866811\n",
      "明天\t2.504077396776274\n",
      "有\t2.504077396776274\n",
      "有没有\t2.504077396776274\n",
      "查下\t2.09861228866811\n",
      "查看\t2.09861228866811\n",
      "查询\t2.504077396776274\n",
      "火车\t2.09861228866811\n",
      "特朗普\t2.504077396776274\n",
      "的\t1.587786664902119\n",
      "看看\t2.504077396776274\n"
     ]
    }
   ],
   "source": [
    "# step 1 声明一个TF-IDF转化器（TfidfTransformer）\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# step 2 根据语料集的词袋向量计算TF-IDF（fit）\n",
    "tfidf_transformer.fit(X.toarray())\n",
    "# step 3 打印TF-IDF信息：比如结合词袋信息，可以查看每个词的TF-IDF值\n",
    "for idx, word in enumerate(vectoerizer.get_feature_names()):\n",
    "  print(\"{}\\t{}\".format(word, tfidf_transformer.idf_[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.3183848\n",
      "   0.          0.          0.42081614  0.          0.          0.20052115\n",
      "   0.50212047  0.          0.          0.          0.50212047  0.          0.\n",
      "   0.42081614  0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.50212047  0.          0.3183848\n",
      "   0.          0.          0.42081614  0.50212047  0.          0.20052115\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.42081614  0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.33116919\n",
      "   0.52228256  0.          0.          0.          0.          0.20857285\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.52228256  0.43771355  0.          0.33116919\n",
      "   0.        ]\n",
      " [ 0.38715525  0.          0.          0.          0.53534183  0.          0.\n",
      "   0.          0.          0.          0.          0.21378805  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.44865824  0.          0.44865824  0.          0.33944982  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.23187059  0.          0.\n",
      "   0.          0.48660646  0.          0.          0.          0.\n",
      "   0.48660646  0.          0.          0.5806219   0.36816103  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.33116919\n",
      "   0.          0.          0.          0.          0.          0.20857285\n",
      "   0.          0.          0.          0.43771355  0.          0.\n",
      "   0.52228256  0.          0.          0.          0.          0.\n",
      "   0.33116919  0.52228256]\n",
      " [ 0.33420711  0.          0.4621274   0.          0.          0.          0.\n",
      "   0.          0.          0.          0.4621274   0.18454996  0.          0.\n",
      "   0.4621274   0.          0.          0.4621274   0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.37686288  0.52110999  0.          0.          0.          0.          0.\n",
      "   0.52110999  0.          0.          0.          0.20810458  0.\n",
      "   0.52110999  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# step 4 将语料集的词袋向量表示转换为TF-IDF向量表示\n",
    "tfidf = tfidf_transformer.transform(X)\n",
    "print(tfidf.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
