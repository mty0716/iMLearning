{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "# MNIST数据集是手写数字数据库，包括60,000个示例的训练集和一个包含10,000个示例的测试集，每一个示例是一张28*28像素的手写数字图像（单一通道）\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置参数和占位符，并将数据集图像转化为张量\n",
    "width = 28 #以像素为单位的图像宽度\n",
    "height = 28 #以像素为单位的图像高度\n",
    "flat = width * height # 一个图像中的像素数\n",
    "class_output = 10 # 问题可能分类的数量\n",
    "\n",
    "x  = tf.placeholder(tf.float32, shape=[None, flat])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, class_output])\n",
    "\n",
    "# 输入图像是28像素×28像素，1个通道（灰度）\n",
    "# 第一个维度是图像的批次编号，可以是任意大小（将其设置为-1）\n",
    "# 第二和第三个维度是宽度和高度，最后一个是图像通道\n",
    "x_image = tf.reshape(x, [-1,28,28,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置卷积层1\n",
    "# 这里过滤器内核大小是5*5; 输入通道为1（灰度）\n",
    "# 需要32个不同的特征映射（这里，32个特征映射表示32个不同的滤波器应用在每个图像上，因此卷积层的输出将是28*28*32）\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 biases for 32 outputs\n",
    "convolve1= tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
    "# ReLU激励函数\n",
    "# ReLU激励函数的作用是，将covolve1中负数出现的任何地方，用0替换\n",
    "h_conv1 = tf.nn.relu(convolve1)\n",
    "# 最大池\n",
    "# 此处最大池的内核为2*2，接移动步长为2，即将内核做滑动 窗口作用于图像，且取窗口内最大值。此处达到了降维的效果，最后输出为14*14*32的矩阵\n",
    "conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置卷积层2\n",
    "# 第一到第二层，输入的是[14x14x32]的图像，过滤器是[5x5x32]的内核\n",
    "# 使用尺寸[5x5x32]的64级的过滤器，即取了64个特征\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #需要64输出的64个偏差\n",
    "convolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')+ b_conv2\n",
    "# ReLU激励函数\n",
    "h_conv2 = tf.nn.relu(convolve2)\n",
    "# 最大池\n",
    "# 最后通过最大池，第二层输出的是[7x7x64]\n",
    "conv2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置第三层完全连接\n",
    "# 完全连接的图层才能使用Softmax并最终创建概率\n",
    "# 完全连接的图层从上一层获取高级过滤的图像，即所有64个图形，并将它们转换为平面数组\n",
    "# 因此，每个矩阵[7x7]将被转换为[49x1]的矩阵，然后所有的64矩阵都将被连接起来，形成一个大小为[3136x1]的数组\n",
    "# 将它连接到另一个尺寸为[1024x1]的图层。所以，这两层之间的重量将是[3136x1024]\n",
    "layer2_matrix = tf.reshape(conv2, [-1, 7*7*64])\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) \n",
    "fcl=tf.matmul(layer2_matrix, W_fc1) + b_fc1# need 1024 biases for 1024 outputs\n",
    "\n",
    "h_fc1 = tf.nn.relu(fcl)#ReLU激励函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置丢弃层，防止过拟合\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "layer_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置输出层（Softmax层）\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1)) #1024个神经元\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) \n",
    "fc=tf.matmul(layer_drop, W_fc2) + b_fc2\n",
    "y_CNN= tf.nn.softmax(fc)# 10 possibilities for digits [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "# 定义损失函数、优化器\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_CNN), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.02\n",
      "step 100, training accuracy 0.74\n",
      "step 200, training accuracy 0.96\n",
      "step 300, training accuracy 0.96\n",
      "step 400, training accuracy 0.98\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.98\n",
      "step 700, training accuracy 0.9\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 0.94\n",
      "step 1000, training accuracy 0.9\n",
      "test accuracy 0.9646\n"
     ]
    }
   ],
   "source": [
    "# 运行会话，开始训练\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 进行1100次迭代\n",
    "for i in range(1100):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, float(train_accuracy)))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
